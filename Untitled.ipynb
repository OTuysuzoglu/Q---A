{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'wikipedia', 'id': '3zotghdk5ibi9ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'cnn', 'id': '3wj1oxy92agboo5nlq4r7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'gutenberg', 'id': '3bdcf01ogxu7zdn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'cnn', 'id': '3ewijtffvo7wwchw6rtya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'gutenberg', 'id': '3urfvvm165iantk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   version                                               data\n",
       "0        1  {'source': 'wikipedia', 'id': '3zotghdk5ibi9ce...\n",
       "1        1  {'source': 'cnn', 'id': '3wj1oxy92agboo5nlq4r7...\n",
       "2        1  {'source': 'gutenberg', 'id': '3bdcf01ogxu7zdn...\n",
       "3        1  {'source': 'cnn', 'id': '3ewijtffvo7wwchw6rtya...\n",
       "4        1  {'source': 'gutenberg', 'id': '3urfvvm165iantk..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json('http://downloads.cs.stanford.edu/nlp/data/coqa/coqa-train-v1.0.json')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>When was the Vat formally opened?</td>\n",
       "      <td>It was formally established in 1475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>what is the library for?</td>\n",
       "      <td>research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>for what subjects?</td>\n",
       "      <td>history, and law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>and?</td>\n",
       "      <td>philosophy, science and theology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>what was started in 2014?</td>\n",
       "      <td>a  project</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Context  \\\n",
       "0  The Vatican Apostolic Library (), more commonl...   \n",
       "1  The Vatican Apostolic Library (), more commonl...   \n",
       "2  The Vatican Apostolic Library (), more commonl...   \n",
       "3  The Vatican Apostolic Library (), more commonl...   \n",
       "4  The Vatican Apostolic Library (), more commonl...   \n",
       "\n",
       "                            Question                               Answer  \n",
       "0  When was the Vat formally opened?  It was formally established in 1475  \n",
       "1           what is the library for?                             research  \n",
       "2                 for what subjects?                     history, and law  \n",
       "3                               and?     philosophy, science and theology  \n",
       "4          what was started in 2014?                           a  project  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning Dataset and Create a new dataset\n",
    "\n",
    "all_list = []\n",
    "for i in range(len(data)):\n",
    "    for j in range(len(data.data[i]['questions'])):\n",
    "        context = data.data[i]['story']\n",
    "        question = data.data[i]['questions'][j]['input_text']\n",
    "        answer = data.data[i]['answers'][j]['input_text']\n",
    "        all_list.append([context,question,answer])\n",
    "\n",
    "coll = ['Context', 'Question', 'Answer']\n",
    "\n",
    "df_new = pd.DataFrame(all_list, columns= coll)\n",
    "df_new.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86917, 3) (21730, 3)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into Train and Test for fine-tunning\n",
    "\n",
    "df_train, df_test = train_test_split(df_new, test_size=0.2, shuffle=True, random_state=42)\n",
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Transformers\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFAutoModelForQuestionAnswering\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'six points'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answering(question, context):\n",
    "    \n",
    "    #Tokenize the context and return TensorFlow tensors\n",
    "    tokenizer = AutoTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "    inputs = tokenizer(question, context, return_tensors= 'tf')\n",
    "    \n",
    "    #passing inputs into the model and return logits\n",
    "    model = TFAutoModelForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "    outputs = model(**inputs)\n",
    "    \n",
    "    start_index = int(tf.math.argmax(outputs.start_logits, axis = -1)[0])\n",
    "    end_index = int(tf.math.argmax(outputs.end_logits, axis = -1)[0])\n",
    "    \n",
    "    predict_answer = inputs.input_ids[0, start_index: end_index + 1]\n",
    "    \n",
    "    \n",
    "    return tokenizer.decode(predict_answer)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_num = np.random.randint(0, len(df_new))\n",
    "\n",
    "qs = df_new['Question'][rand_num]\n",
    "ct = df_new['Context'][rand_num]\n",
    "orginal_answer = df_new['Answer'][rand_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "All the weights of TFBertForQuestionAnswering were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'jimmy and justin are also brothers'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answering(qs,ct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Are they related?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mitchell and his brother, Graham are biking to the store to buy lemons. They want to make a lemonade stand for their friends. In order to do this, they need to buy lemons, sugar, and cups from the store. While they are at the store, they run into their friends Jimmy and Justin. Jimmy and Justin are also brothers. Mitchell and Graham stop to talk to their friends for a bit before they go back to their shopping. After filling up their basket with the items they need to make lemonade, they go to the front of the store to pay. Once they get home, they start making lemonade and set out their table by the sidewalk. They talk to a few of their neighbors as they walk buy and some of them buy some lemonade. After sitting outside for some time, they think about making a sign to let the neighbors know that they have lemonade for sale. Mitchell gets the markers and Graham gets the sign. They work together to make the sign. After putting the sign in front of the table, they find people want much more lemonade. Later Jimmy and Justin stop by and buy some lemonade. Mitchell and Graham talk to their friends about things that Jimmy and Justin would need to do to make their own stand. After their friends leave, Mitchell and Graham count their money and choose to split the money. Each of the boys put the money in their piggy banks.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orginal Answer:  yes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Orginal Answer: ', orginal_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_q = 'where are the money'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "All the weights of TFBertForQuestionAnswering were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'in their piggy banks'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answering(new_q,ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Islamabad is the capital city of Pakistan located within the federal Islamabad Capital Territory. With a population of two million, it is the 10th largest city of Pakistan, while the larger Islamabad-Rawalpindi metropolitan area is the third largest in Pakistan with a population exceeding five\\xa0million. The city is the political seat of Pakistan and is administered by the Islamabad Metropolitan Corporation, supported by the Capital Development Authority (CDA). \\n\\nIslamabad is located in the Pothohar Plateau in the northeastern part of the country, between Rawalpindi District and the Margalla Hills National Park to the north. The region has historically been a part of the crossroads of Punjab and Khyber Pakhtunkhwa with the Margalla Pass acting as the gateway between the two regions. \\n\\nIslamabad was built during the 1960s to replace Karachi as Pakistan's capital. The city's master-plan divides the city into eight zones, including administrative, diplomatic enclave, residential areas, educational sectors, industrial sectors, commercial areas, and rural and green areas. The city is known for the presence of several parks and forests, including the Margalla Hills National Park and Shakarparian Park. The city is home to several landmarks, including the Faisal Mosque, the largest mosque in South Asia and the fourth largest in the world. Other landmarks include the Pakistan's National Monument and Democracy Square.\""
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize the context and return TensorFlow tensors\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "input_ids = tokenizer.encode(new_q,ct)\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "sep_id = input_ids.index(tokenizer.sep_token_id)\n",
    "\n",
    "num_seg_a = sep_id + 1\n",
    "\n",
    "num_seg_b = len(input_ids) - num_seg_a\n",
    "\n",
    "segment_ids = [0]* num_seg_a + [1]*num_seg_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "All the weights of TFBertForQuestionAnswering were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "input_ids_tensor = tf.convert_to_tensor([input_ids])\n",
    "segment_ids_tensor = tf.convert_to_tensor([segment_ids])\n",
    "\n",
    "output = model(input_ids_tensor, token_type_ids=segment_ids_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(text, question):\n",
    "    inputs = tokenizer.encode_plus(question, text, return_tensors=\"tf\", padding=True, truncation=True)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "    # Perform inference\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Get the most likely answer\n",
    "    answer_start_scores = outputs.start_logits.numpy()\n",
    "    answer_end_scores = outputs.end_logits.numpy()\n",
    "\n",
    "    answer_start = tf.argmax(answer_start_scores, axis=1).numpy()[0]\n",
    "    answer_end = tf.argmax(answer_end_scores, axis=1).numpy()[0] + 1\n",
    "\n",
    "    # Decode the answer tokens\n",
    "    answer_tokens = input_ids[0][answer_start:answer_end]\n",
    "    answer = tokenizer.decode(answer_tokens)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in their piggy banks'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer(ct, new_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = int(tf.math.argmax(output.start_logits, axis = -1)[0])\n",
    "end_index = int(tf.math.argmax(output.end_logits, axis = -1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted answer:\n",
      "In their piggy banks\n"
     ]
    }
   ],
   "source": [
    "if end_index > start_index:\n",
    "    ans = tokens[start_index]\n",
    "    for i in range(start_index+1, end_index +1):\n",
    "        if tokens[i][0:2] == '##':\n",
    "            ans = ans + tokens[i][2:]\n",
    "        else:\n",
    "            ans = ans + ' ' + tokens[i]\n",
    "print(\"\\nPredicted answer:\\n{}\".format(ans.capitalize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'an alarm'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orginal_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What does the alarm sound like?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A new camera made by a company named Netatmo has facial recognition software that can tell parents at work that their children have returned from school, or that a package has been taken to their home. It can also tell them if a stranger has entered their home. Janina Mattausch is a product marketing manager for Netatmo. \"The common security cameras at present are not that smart. So, they can tell you if something is moving but they don\\'t necessarily know if it\\'s a human being or, ah, if it\\'s your kids --they don\\'t know the difference, so they will warn you all the time. \" When family members enter a home, the new camera \"recognizes\" ( ) them and sends information to the owner\\'s smartphone. The owner can choose to see the video then or latcr. But if an unknown person enters a home, the camera will send the owner a warning that will cause an alarm to sound on the owner\\'s smartphone. That is what happened recently to a smart home camera owncr named Darrmen. He lives in Paris. \"On a Friday I was at work,atending a big monthly meeting when my phone warned. At first I told myself \\'Oh, it must be a mistake, maybe I have to set the systcm again. \\' -but the notice on my phone was telling me that there was a movement in my flat and also a face that the software did not recognize. \" He watched the video and was very surprised by what he saw. \"I saw a person I did not know with his shoes on. I was watching it live on vidco. So I felt totaly unbelievable, frozen. I asked a workmate to take me back home as fast as possible and I callcd the police on the way. \" With the help of the video, the police found the intruder later that day.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(tf.math.argmax(output.end_logits)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
